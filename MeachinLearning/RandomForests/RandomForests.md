
# 随机森林RandomForests

RF 算法是一种重要的基于Bagging的集成学习方法，可以用来做分类，回归等问题。
随机森林算法是由一系列的决策树组成的，通过自助法Bootstrap 重采样技术，从原始训练样本(大小为m)集中有放回地重复随机抽取m个样本，生成新的训练样本集合，然后根据自助样本集生成k个分类树组成随机森林，新数据的分类结果按照分类树投票多少形成的分数而定。其实质是对决策树算法的一种改进，将多个决策树合并在一起，每棵树的建立依赖于一个独立抽取的样品，森林中的每棵树具有相同的分布，分类误差取决于每一棵树的分类能力和他们之间的相关性。特征选择采用随机的方法去分裂每一个节点，然后比较不同情况下产生的误差。能够检测到的内在估计误差，分类能力和相关性决定选择特征的数目，单科数的分类能力可能很小，但是在随机产生大量的决策树后，一个测试样本可以通过统计每棵树的分类结果，从而选择最可能得分类。

## 随机森林的算法流程

输入：两个参数，构建的决策树的个数N_tree,在决策树的每个节点进行分裂时需要考虑的输入特征的个数k，通常k可以取为logn (以2为底，其中n表示原始数据集中特征的个数)。 
对于单颗决策树的建立，可以分为如下步骤：

- 假设训练样本的个数为m, 则对于每一颗决策树的输入样本的个数都为m，且这m个样本是通过从训练集中有放回地随机抽取得到的。
- 假设训练样本特征的个数为n, 对于每一颗决策树的样本特征是从该n个特征中随机挑选k个，然后从这k个输入特征里选择一个最好的进行分裂。
- 每棵树都一直这样分裂下去，直到该节点的所有训练样例都属于同一类。在决策树分裂过程中不需要减枝。





